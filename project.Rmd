---
title: "Data Visualization Project"
author:
  - name: Antonia Carasel (gr. 505)
  - name: Mircea Vacariuc (gr. 506)
output: html_document
date: '2022-05-07'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = - 1)
```

# TO KEEP IN MIND - la fiecare grafic: ce vrem sa vedem (scris la inceput), tipul de grafic, datele folosite, interpretare

# We can also add population for each state si sa vedem % incidents raportat la populatie

# Daca avem timp la final, it might be nice sa facem si o predictie. Daca nu facem, sa stergem asta din descrierea initiala
# We could also do stuff like PCA maybe,care ar fi mai usoare decat predictia

# Niste categorii cu ce facem scrise la inceput

# !!! Interactive plots. Zoom, tooltip, choosing a variable to display more (https://r-graph-gallery.com/interactive-charts.html)
# Introduction
The objective of this project is to perform an **anlysis of Gun Violence in US** in the past decade. The statistics have as their main purpose discovering trends and correlations between several factors and gun violence and to predict based on the data we have the number of incidents in the future.

We have chosen to employ both *Python* and *R* as programming languages, the former being used for data processing and modelling purposes, and the latter for the actual visualization of the data gathered.

Three data sets have been used, the primary one which includes the topic specific information, and two supporting sets that contain the population for each state according to the 2019 census and the state codes.

The data source for the project is Kaggle.

* Primary dataset: <https://www.kaggle.com/datasets/jameslko/gun-violence-data>
* Population split by state: <https://www.kaggle.com/datasets/peretzcohen/2019-census-us-population-data-by-state>
* US State codes: <https://worldpopulationreview.com/states/state-abbreviations>

# Settings
R specific libraries import
```{r}
library(hrbrthemes)
library(reticulate)
library(ggplot2)
library(hrbrthemes)
library(plotly)
library(tidyverse)
library(gganimate)
library(gifski)
library(viridis)
library(geojsonio)
library(geojsonR)
library(broom)
library(geojsonsf)
```

Python specific libraries import
```{python}
import pandas as pd
import numpy as np
import datetime as dt
```
## Data extraction from the CSV files
```{python}
fileName = 'gun-violence.csv'
fullsetDF = pd.read_csv(fileName)
fileName = 'us_population_by_state.csv'
populationDF = pd.read_csv(fileName)
fileName = 'state_codes.csv'
stateCodesDF = pd.read_csv(fileName)
```
# Data Cleaning

# Check if there are any missing values in any other field. If there are, the value will be replaced with "N/A" - do we need to do this tho?

# Remove unnecesary data

Fields "incident_id" and "incident_url_fields_missing", are not need for our analysis so they were removed.
```{python}
fullsetDF = fullsetDF.drop("incident_id", axis = 1)
fullsetDF = fullsetDF.drop("incident_url_fields_missing", axis = 1)
```
# Processing
We have split the date into months and years sine this information will be used later on when studying the changes over the years and if there are any "seasonal changes".
```{python}
def splitDates(datesList):
    months = []
    years = []
    for i in range(0, len(datesList)):
        value = datesList[i]
        splitDate = dt.datetime.strptime(value, "%Y-%m-%d")
        monthName = splitDate.strftime('%b')
        months.append(monthName)
        years.append(splitDate.year)
    fullsetDF.insert(1, "MONTH", months)
    fullsetDF.insert(2, "YEAR", years)

allDates = fullsetDF['date']
splitDates(allDates)
```
# Congressional district? Is this needed? Maybe only if we add a little bit more information

We would like to see if the type of venue has any impact on the number of incidents that occur. However, there are no clearly defined types and as such, we had to define them ourselves and see which fall into the specific category.The location can be mentioned in several fields, so we will use all of them for our search: `location_description`, `incident_characteristics` and `notes`.

A new field was added called "Location Type"

After this classification, the field "location_description" is no longer useful, so it was deleted. - MEH

```{python}
locationType = ["Bar/Club", "College", "School", "Apartments", "Park", "Restaurant"]
locations = fullsetDF["location_description"]
characteristics = fullsetDF["incident_characteristics"]
notes = fullsetDF["notes"]
```
# cand luam location we need to ignore ce e in (). I need to take this into account - adauga asta in descriere
# need to figure out cum sa facem aici cu bar/club ca in characteristics e pus impreuna, in location e doar unul dintre ele - adauga asta in descriere
# for i in range (0, len(locations)):
#     value = characteristics[i]
#     if type(value) == float:
#         for j in range (0, len(locationType)):
#           if locationType[j].tolower() in value.tolower():
# fullsetDF = fullsetDF.drop("location_description", axis = 1)

The field `incident_characteristics` that can be used to find types of incidents. As described previously, we have defined certain categories and searched the text to find in which categories incident fall in.

Unlike the previous example where only one venue was possible, here there can be more than one or more characteristics describing each incident, which required us to define different fields with a YES/NO response (binary categorical variables).
```{python}
incidentType = ["Home Invasion", "Mass Shooting", "Officer Involved", "Armed Robbery", "Drive-by", "Domestic Violence","Gang"]
fieldNo = fullsetDF.columns.get_loc("incident_characteristics")
matrix = []

for i in range(0, len(incidentType)):
    incidentTypeDiscovered = []
    for j in range(0, len(characteristics)):
        value = characteristics[j]
        if type(value) != float:
          if incidentType[i].lower() in value.lower():
            incidentTypeDiscovered.append("YES")
          else:
            incidentTypeDiscovered.append("NO")
        else:
          incidentTypeDiscovered.append("UNKNOWN")
    fieldName = incidentType[i]
    fullsetDF.insert(fieldNo, fieldName, incidentTypeDiscovered)
```

Field "participant_gender" offers information for all the people involved. We would like to get the actual number and add these fields to the dataframe.
```{python}
genderParticipants = fullsetDF["participant_gender"]
female = []
male = []
for i in range (0, len(genderParticipants)):
    value = genderParticipants[i]
    if type(value) != float:
        no = value.count("Female")
        female.append(no)
        no = value.count("Male")
        male.append(no)
    else:
        female.append(0)
        male.append(0)

fieldNo = fullsetDF.columns.get_loc("participant_gender")
fullsetDF.insert(fieldNo, "FEMALES", female)
fullsetDF.insert(fieldNo, "MALES", male)
```

We would also like to make the distinction between the number of adults, teenagers and children involved in the incidents and we will use the same process as above on the field "participant_age_group".
```{python}
ageParticipants = fullsetDF["participant_age_group"]
children = []
teenagers = []
adults = []
for i in range (0, len(ageParticipants)):
    value = ageParticipants[i]
    if type(value) != float:
        no = value.count("Adult 18+")
        adults.append(no)
        no = value.count("Teen 12-17")
        teenagers.append(no)
        no = value.count("Child 0-11")
        children.append(no)
    else:
        adults.append(0)
        teenagers.append(0)
        children.append(0)
fieldNo = fullsetDF.columns.get_loc("participant_age_group")
fullsetDF.insert(fieldNo, "ADULTS", adults)
fullsetDF.insert(fieldNo, "TEENAGERS", teenagers)
fullsetDF.insert(fieldNo, "CHILDREN", children)
```

# The clean dataframe was saved in a new csv file.
```{python}
fullsetDF.to_csv("gun-violence_processed-data.csv")
```
# Printing a snapshot of the final dataframe to showcase the data we are now working with.


# Definition of variables
This section contains all the variables that will be used going further for plotting. Any data selection or processing will be done here.

Calculating total numbers of
  * incidents that occured 
  * cases that resulted in killings
  * cases that resulted in injuries
in each state, regardless of month or year.
```{python}
totalPerState = []
totalKillingsPerState = []
totalInjuriesPerState = []

for i in range (0, len(stateCodesDF)):
    state = stateCodesDF["State"][i]

    dfHelper = fullsetDF[fullsetDF["state"]==state]['state'].copy(deep=True)
    totalPerState.append(dfHelper.count().item())

    dfHelper = fullsetDF[(fullsetDF["state"] == state) & (fullsetDF['n_killed'] > 0)]['state'].copy(deep=True)
    totalKillingsPerState.append(dfHelper.count().item())

    dfHelper = fullsetDF[(fullsetDF["state"] == state) & (fullsetDF['n_injured'] > 0)]['state'].copy(deep=True)
    totalInjuriesPerState.append(dfHelper.count().item())

stateCodes = stateCodesDF["Code"]
```

# Graphs
## Initial exploration of the dataset
### **Chart Type:** Barplot with one numeric variable
We have defined a function for this type of plot and called it for each of the scenarios.
```{r}
initial_eda_barplots <- function(all_labels, all_values, x_name, y_name, plot_title, colour){
  
  data=data.frame(name = all_labels, value = all_values)

  totalIncidentsBarPlot <- ggplot(data, aes(x=name, y = value)) + geom_bar(stat = "identity", width=0.7, fill = colour) + 
    xlab(x_name) + 
    ylab(y_name) +
    ggtitle(plot_title) +
    theme(
      plot.title = element_text(hjust = 0.5),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white"), 
      axis.text.x = element_text(angle = 90, vjust = 0.5)
  )
  ggplotly(totalIncidentsBarPlot)
}
```

**Variable: Total number of incidents that occured**

We want to see the distribution of the total number of incidents per each state. We will use the `totalPerState` dataframe and the codes from the `stateCodes` array.

```{r}
r_totalPerState <- py$totalPerState
r_labels <- py$stateCodes

initial_eda_barplots(r_labels, r_totalPerState, "State Code", "Number of incidents", "Distribution of incidents per State", "#091CC1")
```

The general level of incidents can roughly be found somewhere in the interval [0,5000], but we do see some outliers - states have a significantly higher number of gun-involved cases.

**Variable: Total number of cases that resulted in killings**
```{r}
r_totalKillingsPerState <- py$totalKillingsPerState

initial_eda_barplots(r_labels, r_totalKillingsPerState, "State Code", "Number of killings", "Distribution of cases that resulted in killings per State", "#652194")
```

**Variable: Total number of cases that resulted in injuries**
```{r}
r_totalInjuriesPerState <- py$totalInjuriesPerState

initial_eda_barplots(r_labels, r_totalInjuriesPerState, "State Code", "Number of injuries", "Distribution of cases that resulted in injuries per State", "#134611")
```

Outlier values can be noticed in the last two charts as well. Given this observation, it would make sense to realize another chart - a Boxplot - that would specifically highlight this information. Even though boxplots can sometimes be missleading because of the loss of information, our purpose for this scenario is to identify those states that do not fall into the IQR (Interquantile Range), purpose which makes this type of chart appropiate.

```{python}

```

### **Chart Type:** Boxplot with three series
**Variables: Total number of incidents, firearm deaths and injuries, respectively**
```{r}
r_totalPerState <- py$totalPerState
r_totalKillingsPerState <- py$totalKillingsPerState
r_totalInjuriesPerState <- py$totalInjuriesPerState

p <- boxplot(r_totalPerState, r_totalKillingsPerState, r_totalInjuriesPerState,
main = "Outlier variables - States that have higher criminality",
names = c("Number of incidents", "Number of killings", "Number of injuries"),
col = c("#091CC1","#652194", "#134611")
)
p
```

### **Chart Type:** Doughnut Plot
We have decided to further investigate the outlier states so as to better understand the factors that led to an increased number of incidents involving firearms.

The first type of analysis targets the age categories. For this purpose, the data was visualized in separate doughnut charts as seen below.

Calculating the percentage of Child, Teenager and Adult participants for each state.
```{python}
outlierList = np.array(["Pennsylvania", "California", "Colorado"])
totalsStates = np.zeros(shape=(len(outlierList),3), dtype = float)
categories = np.array(["CHILDREN", "TEENAGERS", "ADULTS"])

for i in range(0,len(outlierList)):
    state = outlierList[i]
    array = []

    dfHelper = fullsetDF[fullsetDF["state"]==state][categories[0]].copy(deep=True)
    totalsStates[i][0] = dfHelper.sum().item()

    dfHelper = fullsetDF[fullsetDF["state"]==state][categories[1]].copy(deep=True)
    totalsStates[i][1] = dfHelper.sum().item()

    dfHelper = fullsetDF[fullsetDF["state"]==state][categories[2]].copy(deep=True)
    totalsStates[i][2] = dfHelper.sum().item()

# Percentages per state for each group
for i in range(0, len(outlierList)):
    total = totalsStates[i][0] + totalsStates[i][1] + totalsStates[i][2]
    for j in range(0, 3):
        totalsStates[i][j] = float("{:.4f}".format(totalsStates[i][j] / total))*100
```

```{r}
donut_plot_labels <- function(all_labels, all_values) {
  
data = data.frame(name = all_labels, value = all_values)

data$ymax = cumsum(all_values)
data$ymin = c(0, head(data$ymax, n=-1))

data$labelPosition <- (data$ymax + data$ymin) / 2
data$label <- paste0(data$name, ": ", data$value, "%")

ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=name)) + 
  geom_rect() +
  geom_text( x=2, aes(y=labelPosition, label=label, color=name), size=3) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  coord_polar(theta="y") +
  xlim(c(-1, 4))
}
```

**Variables: Percentage of each age group involved in an incident per state and across the states.**
```{r}
r_categories <- py$categories
matrix <- py$totalsStates
for(row in 1 : nrow(matrix)){
  r_totalsStates<- matrix[row,]
  print(donut_plot_labels(r_categories, r_totalsStates))
}
```

We would also like to have an overview of the age groups across the outlier states to see if there are any differences between the states. We could assume that some of the states have a higher percentage of teenagers involved in gun-voilence than others.
```{python}
# Percentages per group for each state
for j in range(0, 3):
    total = totalsStates[0][j] + totalsStates[1][j] + totalsStates[2][j]
    for i in range(0, len(outlierList)):
        totalsStates[i][j] = float("{:.4f}".format(totalsStates[i][j] / total))*100
totalsStates = totalsStates.transpose()
```

```{r}
r_outlierList <- py$outlierList

matrix <- py$totalsStates
for(row in 1 : nrow(matrix)){
  r_totalsStates<- matrix[row,]
  print(donut_plot_labels(r_outlierList, r_totalsStates))
}
```

# The differences between the states are - FINISH HERE

### **Chart Type:** Circular BarPlot with one numeric variable
The purpose of the next section is to identify the number of guns used in all the incidents per state. We have noticed that there are several incidents with at least 3 guns involved.
```{python}
gunsTotalPerState = []
for i in range (0, len(stateCodesDF)):
    state = stateCodesDF["State"][i]
    dfHelper = fullsetDF[fullsetDF["state"]==state]["n_guns_involved"].copy(deep=True)
    gunsTotalPerState.append(dfHelper.sum().item())
gunsTotalPerState = np.array(gunsTotalPerState)
```

```{r}
circular_barplot <- function(all_labels, all_values, x_name, y_name, plot_title, colour){
  
  data=data.frame(name = all_labels, value = all_values)

  totalIncidentsBarPlot <- ggplot(data, aes(x=name, y = value)) + geom_bar(stat = "identity", width=0.7, fill = colour) + 
    xlab(x_name) + 
    ylab(y_name) +
    ggtitle(plot_title)+
    theme(
      plot.title = element_text(hjust = 0.5),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white")
  ) +
  coord_polar(start = 0)
  
  options(repr.plot.width = 40, repr.plot.height = 40)
  totalIncidentsBarPlot
}
```

```{r}
r_gunsTotalPerState <- py$gunsTotalPerState

circular_barplot(r_labels, r_gunsTotalPerState, "State Code", "Number of guns", "Distribution of no of guns involved per State", "#091CC1")
```

We can clearly see that there are several states where the number of guns is a lot higher, specifically California, Florida, Texas and Illinois.

As we remember from the initial plots, these are the exact states that had the highest number of incidents as well.
### **Chart Type:** Heatmap
The 2 categorical variables that are taken into account for this type of chart are the `IncidentType` and the `States`. We have previously split the incidet type into 7 different categories. We would now like to make an analysis of the causes of gun-violence, i.e. how often each type occurs for the individual states.
```{python}
typeTotalPerState = np.empty(shape=(len(incidentType)*len(stateCodesDF)))
it = 0
for i in range(0, len(incidentType)):
    incident = incidentType[i]

    for j in range (0, len(stateCodesDF)):
        state = stateCodesDF["State"][j]
        dfHelper = fullsetDF[(fullsetDF["state"]==state) & (fullsetDF[incident] == "YES")][incident].copy(deep=True)

        typeTotalPerState[it] = dfHelper.count()
        it = it + 1
```

```{r}
r_typeTotalPerState <- py$typeTotalPerState
x <- py$stateCodes
y <- py$incidentType
data <- expand.grid(X=x, Y=y)

data$Z <- r_typeTotalPerState

ggplot(data, aes(X, Y, fill=Z)) + 
 geom_tile() + 
  scale_fill_distiller(palette = "Greens") + 
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5)
  )
```


### **Chart Type:** Trending Animated Bar Chart
We first calculate the number of people injured or killed (respectively) for each state during each year available in the given dataset. We noticed that for certain years and states, there were no incidents reported and as such, those entries needed to be added to the dataframe with the value 0 in order to be able to plot the data.
```{python}
statesAll = stateCodes = stateCodesDF["State"]
def insertRow(row_number, df, row_value):
    start_upper = 0
    end_upper = row_number
    start_lower = row_number
    end_lower = df.shape[0]
    upper_half = [*range(start_upper, end_upper, 1)]
    lower_half = [*range(start_lower, end_lower, 1)]
    lower_half = [x.__add__(1) for x in lower_half]
    index_ = upper_half + lower_half
    df.index = index_
    df.loc[row_number] = row_value

peopleKilledByStateandDate = fullsetDF[["state", "YEAR", "n_killed"]]
peopleKilledByStateandDate = peopleKilledByStateandDate.groupby([peopleKilledByStateandDate["state"], peopleKilledByStateandDate["YEAR"]], as_index=False).agg({"n_killed" : "sum"})
peopleKilledByStateandDate.rename(columns = {'n_killed':'var'}, inplace = True)

def dataCleaning(dataframe):
  allYears = [2013, 2014, 2015, 2016, 2017, 2018]
  for i in range(0, len(statesAll)):
      for j in range(i*6, i*6+6):
          year = allYears[j - i*6]
          if (dataframe.iloc[j]["YEAR"] != year):
              insertValue = [statesAll[i], year, 0]
              insertRow(j, dataframe, insertValue)
              dataframe = dataframe.sort_index(axis=0)
              j = j-1

dataCleaning(peopleKilledByStateandDate)
```

```{r}
rankingPlot <- function(data, plot_title){

  totalIncidentsRankingBarChart <- ggplot(data, aes(rank, group = state, fill = as.factor(state), color = as.factor(state))) + 
    geom_tile(aes(y = var/2, height = var, width = 0.9), alpha = 0.8, color = NA) +
    geom_text(aes(y = 0, label = paste(state, " ")), vjust = 0.2, hjust = 1, size = 6) +
    geom_text(aes(y = var, label = n_lbl, hjust = 0), size = 6) +
    coord_flip(clip = "off", expand = FALSE) +
    scale_y_continuous(labels = scales::comma) +
    scale_x_reverse() +
    theme(
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white"),
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      plot.title = element_text(size = 25),
      legend.position = "none",
      plot.margin = margin(4, 4, 4, 4, "cm")
  )
  anim <- totalIncidentsRankingBarChart + 
    transition_states(YEAR, transition_length = 5, state_length = 5) +
    view_follow(fixed_x = TRUE) +
    labs(title = plot_title)
    
  
  animate(anim, 200, fps = 20,  width = 1200, height = 1000, 
        renderer = gifski_renderer("gganim.gif"))
}
```

```{r}
r_totalPerState <- py$peopleKilledByStateandDate

dataPrep <- function(dataframe){
  dataframe <- dataframe %>%
  group_by(YEAR) %>%
  mutate(rank = rank(-var),
         n_rel = var/var[rank==1],
         n_lbl = paste0(round(var, 2))) %>%
  group_by(state) %>%
  filter(rank <=10) %>%
  ungroup()
}

r_totalPerState <- dataPrep(r_totalPerState)

rankingPlot(r_totalPerState, 'Ranking of total number of deaths per year: {closest_state}')
```


The same process described above was followed for the number of injuries.
```{python}
peopleInjuredByStateandDate = fullsetDF[["state", "MONTH", "YEAR", "n_injured"]]
peopleInjuredByStateandDate = peopleInjuredByStateandDate.groupby([peopleInjuredByStateandDate["state"], peopleInjuredByStateandDate["YEAR"]], as_index=False).agg({"n_injured" : "sum"})

peopleInjuredByStateandDate.rename(columns = {'n_injured':'var'}, inplace = True)

dataCleaning(peopleInjuredByStateandDate)
```

```{r}
r_totalPerState <- py$peopleInjuredByStateandDate

r_totalPerState <- dataPrep(r_totalPerState)

rankingPlot(r_totalPerState, 'Ranking of total number of injuries per year: {closest_state}')
```

### **Chart Type:** Doughnut Chart
We want

Variables: Total number of incidents, total number of incidents per state => procent

Calculating total number of incidents per state and adding them into a dictionary.
The states with incident percentages less than 1% will be categorized as others.
```{python}
totalPerState = []
incidentsStatesArray = np.array(fullsetDF['state'].to_numpy())
for i in range(0, len(stateCodesDF)):
    state = stateCodesDF["State"][i]
    totalPerState.append(incidentsStatesArray[incidentsStatesArray == state].shape[0])
        
DictStateIncident = {"Others": 0}
dfHelper = fullsetDF[fullsetDF["state"]==state]['state'].copy(deep=True)
totalIncidents = len(dfHelper)

incidentsPerStatePercentages = (np.array(totalPerState) / totalIncidents)
for i in range(0,len(stateCodes)):
    if incidentsPerStatePercentages[i] > 1:
        DictStateIncident[stateCodes[i]] = round(incidentsPerStatePercentages[i], 2)
    else:
        DictStateIncident["Others"] = DictStateIncident["Others"] + round(incidentsPerStatePercentages[i], 2)
        
statesForDonut = np.array(list(DictStateIncident.keys()))
valuesForDonut = np.array(list(DictStateIncident.values()))
```

```{r}
donut_plot <- function(all_labels, all_values) {
  
data = data.frame(name = all_labels, value = all_values)

data$ymax = cumsum(all_values)
data$ymin = c(0, head(data$ymax, n=-1))

ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=name)) + 
  geom_rect() +
  coord_polar(theta="y") +
  xlim(c(2, 4))
}
```

```{r}
r_labels <- py$statesForDonut
r_percentagesPerState <- py$valuesForDonut

donut_plot(r_labels, r_percentagesPerState)
```

Calculating the number of incidents per region: NE, NW, SW, SE.

We consider the center position the geographic center of the United States. This is a point approximately 32 km north of Belle Fourche, South Dakota at LAT. 39°50' LONG. −98°35'
```{python}
DictIncidentsPerRegion = {"NE": 0, "NW": 0, "SW": 0, "SE": 0}

incidentsCoordinates = fullsetDF[["latitude", "longitude"]]

for i in range(0, len(incidentsCoordinates)):
    if incidentsCoordinates["latitude"][i] > 39 and incidentsCoordinates["longitude"][i] > -98:
        DictIncidentsPerRegion["NE"] += 1
    if incidentsCoordinates["latitude"][i] > 39 and incidentsCoordinates["longitude"][i] < -98:
        DictIncidentsPerRegion["NW"] += 1
    if incidentsCoordinates["latitude"][i] < 39 and incidentsCoordinates["longitude"][i] < -98:
        DictIncidentsPerRegion["SW"] += 1
    if incidentsCoordinates["latitude"][i] < 39 and incidentsCoordinates["longitude"][i] > -98:
        DictIncidentsPerRegion["SE"] += 1

totalNoIncidents = sum(DictIncidentsPerRegion.values())
  
regions = np.array(list(DictIncidentsPerRegion.keys()))
incidentsPerRegions = np.round(np.array((np.array(list(DictIncidentsPerRegion.values())) / totalNoIncidents) * 100), 2)

```

```{r}
r_regions <- py$regions
r_incidentsPerRegion <- py$incidentsPerRegions

donut_plot_labels(r_regions, r_incidentsPerRegion)
```

### **Chart Type:** Lollipop chart with one numeric variable
In this section we want to highlight the top 25 and the bottom 25 news websites that reported crimes, which would help decide which online newspaper are the most and least trustworthy.
```{python}
sourcesPerIncident = fullsetDF[["date", "sources"]]

DictSourcesAndIncidents = {"pittsburgh.cbslocal.com" : 0}
for i in range (0, len(sourcesPerIncident["sources"])):
    try:
        sourcesArray = sourcesPerIncident["sources"][i].split("||")
    except:
        continue
    for source in sourcesArray:
        URI = source.strip().partition("//")[2]
        URL = URI.partition("/")[0]
        if URL in DictSourcesAndIncidents:
            DictSourcesAndIncidents[URL] += 1
        else:
            DictSourcesAndIncidents[URL] = 0

lessIncidentsPerSource = dict(filter(lambda elem: elem[1] != 0, DictSourcesAndIncidents.items()))

sort_by_value = lambda DictSourcesAndIncidents: DictSourcesAndIncidents[1]
sortedSourcesDict = sorted(DictSourcesAndIncidents.items(), key = sort_by_value, reverse=True)

sourcesName = []
sourceNews = []
for x in list(sortedSourcesDict)[0:25]:
    sourcesName.append(x[0])
    sourceNews.append(x[1])
    
sortedSourcesLeastTrustful = sorted(lessIncidentsPerSource.items(), key = sort_by_value)

sourcesLeastTrustful = []
appearancesLeastTrusful = []
for x in list(sortedSourcesLeastTrustful)[0:25]:
    sourcesLeastTrustful.append(x[0])
    appearancesLeastTrusful.append(x[1])
```


```{r}
library(plotly)

lollipop_function <- function(sources, appearances, title) {
    
    data <- data.frame(x = sources, y = appearances)
    
    p <- ggplot(data, aes(x=x, y=y)) +
      geom_segment( aes(x=reorder(x, y), xend=x, y=0, yend=y), color="grey") +
      geom_point( color="orange", size=4, fill=alpha("orange", 0.3), alpha=0.7, shape=21, stroke=2) +
      theme_light() +
      coord_flip() +
      ggtitle(title) +
      scale_size(range=c(2,12), guide="none") +
      theme(
        panel.grid.major.x = element_blank(),
        panel.border = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(size = 12)
      ) +
      xlab("") +
      ylab("Number of incidents reported for the whole period")
    
    ggplotly(p)
}
```

```{r}
r_source <- py$sourcesName
r_news <- py$sourceNews

lollipop_function(r_source, r_news, "The most trustworthy websites that reported gun-violence incidents")
```

```{r}
r_source <- py$sourcesLeastTrustful
r_news <- py$appearancesLeastTrusful

lollipop_function(r_source, r_news, "The least trustworthy websites that reported gun-violence incidents")
```

### **Chart Type:** Choropleth charts


```{python}
incidentsPerState = fullsetDF["state"].value_counts(ascending=False)

statesForMap = np.array(incidentsPerState.index)
incidentsForMap = np.array(incidentsPerState.values)

```

# ```{r}
# file <- system.file("examples", "us_states.json", package = "geojsonio")
# spdf <- geojson_read(file, what = "sp")
# 
# spdf_fortified <- tidy(spdf, region = "id")
# 
# r_states <- py$statesForMap
# r_incidents <- py$incidentsForMap
# 
# numericData <- data.frame(id = r_states, incidents = r_incidents)
# 
# spdf_fortified <- merge(spdf_fortified, numericData, by="id")
# ```

# ```{r}
# 
# ggplot(data = spdf_fortified, aes( x = long, y = lat, group = group)) +
#     geom_polygon(aes(fill = incidents), color = "black", size = 0.1) + 
#     coord_map() +
#     labs(
#       title = "US states map",
#       subtitle = "Number of gun-violence incidents per state"
#     ) +
#     scale_fill_gradient(high = "#e34a33", low = "#fee8c8", guide = "colorbar") +
#     theme(
#       text = element_text(color = "#22211d"),
#       plot.background = element_rect(fill = "#f5f5f2", color = NA),
#       panel.background = element_rect(fill = "#f5f5f2", color = NA),
#       legend.background = element_rect(fill = "#f5f5f2", color = NA),
#   
#       plot.title = element_text(size= 14, hjust=0.01, color = "#4e4d47", margin = margin(b = -0.1, t = 0.4, l = 2, unit = "cm")),
#       plot.subtitle = element_text(size= 12, hjust=0.01, color = "#4e4d47", margin = margin(b = -0.1, t = 0.43, l = 2, unit = "cm")),
#       plot.caption = element_text( size=12, color = "#4e4d47", margin = margin(b = 0.3, r=-99, unit = "cm") ),
#   
#       legend.position = c(0.9, 0.2)
#     ) +
#     xlim(c(-130, -65)) +
#     ylim(c(20, 50))
#     
# ```

**Chart Type:**
We want to see the level of crime for each state proportional to the size of the population. We have previously calcuated the respective percentages and they will be ploted below, also adding tooltips to offer more details for each state.
```{r}

```




# Overall Conclusions